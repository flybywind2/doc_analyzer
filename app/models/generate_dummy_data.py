"""
Generate dummy data for testing
"""
from datetime import datetime, timedelta
import random
from sqlalchemy.orm import Session
from app.models.user import User
from app.models.department import Department
from app.models.application import Application
from app.models.evaluation import EvaluationHistory
from app.services.auth import get_password_hash


def generate_dummy_data(db: Session):
    """Generate dummy data for testing"""
    
    print("ğŸ”„ Generating dummy data...")
    
    # Check if dummy data already exists
    existing_apps = db.query(Application).count()
    if existing_apps > 0:
        print(f"âš ï¸  Dummy data already exists ({existing_apps} applications). Skipping...")
        return
    
    # Create departments
    departments_data = [
        {"name": "í”Œë«í¼ê°œë°œíŒ€", "total_employees": 50},
        {"name": "AIì—°êµ¬íŒ€", "total_employees": 30},
        {"name": "ë°ì´í„°ë¶„ì„íŒ€", "total_employees": 25},
        {"name": "ì„œë¹„ìŠ¤ê°œë°œíŒ€", "total_employees": 40},
        {"name": "ì¸í”„ë¼ìš´ì˜íŒ€", "total_employees": 20},
    ]
    
    departments = []
    for dept_data in departments_data:
        dept = db.query(Department).filter(Department.name == dept_data["name"]).first()
        if not dept:
            dept = Department(**dept_data)
            db.add(dept)
            db.flush()
        departments.append(dept)
    
    db.commit()
    print(f"âœ… Created {len(departments)} departments")
    
    # Create reviewers (one per department)
    reviewers = []
    for i, dept in enumerate(departments, 1):
        username = f"reviewer{i}"
        user = db.query(User).filter(User.username == username).first()
        if not user:
            user = User(
                username=username,
                password_hash=get_password_hash("password123!"),
                name=f"{dept.name} ì‹¬ì‚¬ìœ„ì›",
                role="reviewer",
                department_id=dept.id,
                is_active=True,
                is_first_login=False
            )
            db.add(user)
            db.flush()
        reviewers.append(user)
    
    db.commit()
    print(f"âœ… Created {len(reviewers)} reviewers")
    
    # Dummy application templates
    templates = [
        {
            "subject": "ê³ ê° ìƒë‹´ ìë™í™” ì±—ë´‡ êµ¬ì¶•",
            "current_work": "í˜„ì¬ ê³ ê° ìƒë‹´ì€ ëª¨ë‘ ìˆ˜ë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ê³  ìˆì–´ ìƒë‹´ì‚¬ ì—…ë¬´ ë¶€ë‹´ì´ í½ë‹ˆë‹¤.",
            "pain_point": "ë°˜ë³µì ì¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ìœ¼ë¡œ ìƒë‹´ì‚¬ ì‹œê°„ì˜ 70%ê°€ ì†Œìš”ë˜ê³ , ì•¼ê°„/ì£¼ë§ ëŒ€ì‘ì´ ì–´ë µìŠµë‹ˆë‹¤.",
            "improvement_idea": "LLM ê¸°ë°˜ ì±—ë´‡ì„ êµ¬ì¶•í•˜ì—¬ FAQ ìë™ ì‘ë‹µ ë° 1ì°¨ ìƒë‹´ì„ ì²˜ë¦¬í•˜ê³ , ë³µì¡í•œ ë¬¸ì˜ë§Œ ìƒë‹´ì‚¬ì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.",
            "expected_effect": "ìƒë‹´ì‚¬ ì—…ë¬´ ì‹œê°„ 50% ì ˆê°, 24/7 ê³ ê° ëŒ€ì‘ ê°€ëŠ¥, ê³ ê° ë§Œì¡±ë„ í–¥ìƒ",
            "hope": "LLM ëª¨ë¸ ì„ ì • ë° íŠœë‹ ì§€ì›, ì±—ë´‡ UI/UX ê°œë°œ ì§€ì›",
            "ai_category": "LLM",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 3},
                {"category": "AI/ML", "skill": "LangChain", "level": 2}
            ]
        },
        {
            "subject": "ì‚¬ë‚´ ë¬¸ì„œ ê²€ìƒ‰ RAG ì‹œìŠ¤í…œ ê°œë°œ",
            "current_work": "ì‚¬ë‚´ ê¸°ìˆ  ë¬¸ì„œê°€ ì—¬ëŸ¬ ê³³ì— ë¶„ì‚°ë˜ì–´ ìˆì–´ í•„ìš”í•œ ì •ë³´ë¥¼ ì°¾ëŠ”ë° ë§ì€ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤.",
            "pain_point": "ë¬¸ì„œ ê²€ìƒ‰ì— í‰ê·  30ë¶„ ì´ìƒ ì†Œìš”, ê²€ìƒ‰ ì •í™•ë„ ë‚®ìŒ, ì—…ë°ì´íŠ¸ëœ ì •ë³´ ì°¾ê¸° ì–´ë ¤ì›€",
            "improvement_idea": "RAG ì‹œìŠ¤í…œìœ¼ë¡œ Confluence, Wiki, ê³µìœ  ë“œë¼ì´ë¸Œì˜ ë¬¸ì„œë¥¼ í†µí•© ê²€ìƒ‰í•˜ê³  ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ ì œê³µ",
            "expected_effect": "ë¬¸ì„œ ê²€ìƒ‰ ì‹œê°„ 80% ë‹¨ì¶•, ì •ë³´ ì ‘ê·¼ì„± í–¥ìƒ, ì—…ë¬´ ìƒì‚°ì„± ì¦ëŒ€",
            "hope": "ë²¡í„° DB êµ¬ì¶• ì§€ì›, ì„ë² ë”© ëª¨ë¸ ìµœì í™” ì§€ì›",
            "ai_category": "RAG",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 4},
                {"category": "ë°ì´í„°ë² ì´ìŠ¤", "skill": "Vector DB", "level": 2}
            ]
        },
        {
            "subject": "ì œí’ˆ ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ",
            "current_work": "í˜„ì¬ëŠ” ê³¼ê±° íŒë§¤ ë°ì´í„° ê¸°ë°˜ì˜ ë‹¨ìˆœ í‰ê· ìœ¼ë¡œ ìˆ˜ìš”ë¥¼ ì˜ˆì¸¡í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "pain_point": "ê³„ì ˆì„±, í”„ë¡œëª¨ì…˜, ì™¸ë¶€ ìš”ì¸ ë¯¸ë°˜ì˜ìœ¼ë¡œ ì˜ˆì¸¡ ì •í™•ë„ 60% ìˆ˜ì¤€, ì¬ê³  ë¶€ì¡± ë˜ëŠ” ê³¼ì‰ ë°œìƒ",
            "improvement_idea": "ML ëª¨ë¸(XGBoost, LSTM)ì„ í™œìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë³€ìˆ˜ë¥¼ ê³ ë ¤í•œ ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•",
            "expected_effect": "ì˜ˆì¸¡ ì •í™•ë„ 85% ì´ìƒ, ì¬ê³  ë¹„ìš© 30% ì ˆê°, í’ˆì ˆë¥  50% ê°ì†Œ",
            "hope": "ì‹œê³„ì—´ ë¶„ì„ ì§€ë„, ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì§€ì›",
            "ai_category": "ML",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 4},
                {"category": "AI/ML", "skill": "scikit-learn", "level": 3},
                {"category": "AI/ML", "skill": "XGBoost", "level": 2}
            ]
        },
        {
            "subject": "ì œì¡° ë¶ˆëŸ‰í’ˆ ìë™ ê²€ì¶œ ì‹œìŠ¤í…œ",
            "current_work": "ì œì¡° ë¼ì¸ì—ì„œ ë¶ˆëŸ‰í’ˆ ê²€ì‚¬ëŠ” ìœ¡ì•ˆ ê²€ì‚¬ë¡œ ì§„í–‰ë˜ë©° ê²€ì‚¬ìì˜ í”¼ë¡œë„ì— ë”°ë¼ ì •í™•ë„ê°€ ë‹¬ë¼ì§‘ë‹ˆë‹¤.",
            "pain_point": "ë¶ˆëŸ‰í’ˆ ê²€ì¶œë¥  75%, ê²€ì‚¬ ì‹œê°„ ì œí’ˆë‹¹ 10ì´ˆ ì†Œìš”, ì¸ë ¥ ì˜ì¡´ì ",
            "improvement_idea": "ë”¥ëŸ¬ë‹ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸(CNN)ë¡œ ì‹¤ì‹œê°„ ë¶ˆëŸ‰í’ˆ ìë™ ê²€ì¶œ ì‹œìŠ¤í…œ êµ¬ì¶•",
            "expected_effect": "ê²€ì¶œë¥  95% ì´ìƒ, ê²€ì‚¬ ì‹œê°„ 1ì´ˆë¡œ ë‹¨ì¶•, ì¸ë ¥ 50% ì ˆê°",
            "hope": "í•™ìŠµ ë°ì´í„° ë¼ë²¨ë§ ì§€ì›, ëª¨ë¸ ê²½ëŸ‰í™” ë° ì—£ì§€ ë°°í¬ ì§€ì›",
            "ai_category": "DL",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 3},
                {"category": "AI/ML", "skill": "TensorFlow", "level": 3},
                {"category": "AI/ML", "skill": "Computer Vision", "level": 2}
            ]
        },
        {
            "subject": "ì˜ì—… í”„ë¡œì„¸ìŠ¤ ìë™í™” AI Agent",
            "current_work": "ì˜ì—… íŒ€ì˜ ì¼ì¼ ì—…ë¬´ëŠ” ë¦¬ë“œ ë°œêµ´, ì´ë©”ì¼ ë°œì†¡, ë¯¸íŒ… ì¼ì • ì¡°ìœ¨ ë“± ë°˜ë³µ ì‘ì—…ì´ ë§ìŠµë‹ˆë‹¤.",
            "pain_point": "ì˜ì—…ì‚¬ì› ì‹œê°„ì˜ 60%ê°€ í–‰ì • ì—…ë¬´ì— ì†Œìš”, ì‹¤ì œ ì˜ì—… í™œë™ ì‹œê°„ ë¶€ì¡±",
            "improvement_idea": "AI Agentë¡œ ë¦¬ë“œ ë°œêµ´, ì´ë©”ì¼ ìë™ ì‘ì„±/ë°œì†¡, ì¼ì • ì¡°ìœ¨, CRM ì—…ë°ì´íŠ¸ ìë™í™”",
            "expected_effect": "í–‰ì • ì—…ë¬´ ì‹œê°„ 70% ì ˆê°, ì˜ì—… í™œë™ ì‹œê°„ 2ë°° ì¦ê°€, ë§¤ì¶œ 30% ì¦ëŒ€",
            "hope": "ë©€í‹° ìŠ¤í… ì›Œí¬í”Œë¡œìš° ì„¤ê³„ ì§€ì›, API ì—°ë™ ì§€ì›",
            "ai_category": "AI Agent",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 3},
                {"category": "AI/ML", "skill": "LangChain", "level": 2},
                {"category": "ìë™í™”", "skill": "RPA", "level": 2}
            ]
        },
        {
            "subject": "ë§ˆì¼€íŒ… ìº í˜ì¸ íš¨ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
            "current_work": "ë§ˆì¼€íŒ… ë°ì´í„°ê°€ ì—¬ëŸ¬ í”Œë«í¼ì— ë¶„ì‚°ë˜ì–´ ìˆì–´ í†µí•© ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤.",
            "pain_point": "ë°ì´í„° ìˆ˜ì§‘ì— 2ì¼ ì†Œìš”, ìˆ˜ë™ ë¶„ì„ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ì§€ì—°, ì˜ì‚¬ê²°ì • ì†ë„ ì €í•˜",
            "improvement_idea": "AI ê¸°ë°˜ ë°ì´í„° í†µí•© ë° ìë™ ë¶„ì„ ëŒ€ì‹œë³´ë“œ êµ¬ì¶•, ì˜ˆì¸¡ ì¸ì‚¬ì´íŠ¸ ì œê³µ",
            "expected_effect": "ë¶„ì„ ì‹œê°„ 90% ë‹¨ì¶•, ì‹¤ì‹œê°„ ì¸ì‚¬ì´íŠ¸ ì œê³µ, ROI 20% í–¥ìƒ",
            "hope": "BI ë„êµ¬ ì—°ë™ ì§€ì›, ì˜ˆì¸¡ ë¶„ì„ ëª¨ë¸ ê°œë°œ ì§€ì›",
            "ai_category": "ë°ì´í„°ë¶„ì„",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 4},
                {"category": "ë°ì´í„° ë¶„ì„", "skill": "Pandas", "level": 4},
                {"category": "ì‹œê°í™”", "skill": "Tableau", "level": 3}
            ]
        },
        {
            "subject": "ì½”ë“œ ë¦¬ë·° ìë™í™” AI ì–´ì‹œìŠ¤í„´íŠ¸",
            "current_work": "ì½”ë“œ ë¦¬ë·°ëŠ” ì‹œë‹ˆì–´ ê°œë°œìê°€ ìˆ˜ë™ìœ¼ë¡œ ì§„í–‰í•˜ë©° ì‹œê°„ì´ ë§ì´ ì†Œìš”ë©ë‹ˆë‹¤.",
            "pain_point": "ë¦¬ë·° ëŒ€ê¸° ì‹œê°„ í‰ê·  2ì¼, ì‹œë‹ˆì–´ ê°œë°œì ì—…ë¬´ ë¶€ë‹´, ë¦¬ë·° í’ˆì§ˆ í¸ì°¨",
            "improvement_idea": "LLM ê¸°ë°˜ ì½”ë“œ ë¦¬ë·° AIë¡œ ë²„ê·¸, ë³´ì•ˆ ì·¨ì•½ì , ì½”ë”© ì»¨ë²¤ì…˜ ìë™ ê²€í† ",
            "expected_effect": "ë¦¬ë·° ì‹œê°„ 50% ë‹¨ì¶•, ì½”ë“œ í’ˆì§ˆ í–¥ìƒ, ì‹œë‹ˆì–´ ê°œë°œì ë¶€ë‹´ ê°ì†Œ",
            "hope": "ì½”ë“œ ë¶„ì„ ëª¨ë¸ íŒŒì¸íŠœë‹ ì§€ì›, Git ì—°ë™ ì§€ì›",
            "ai_category": "LLM",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 4},
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Java", "level": 3},
                {"category": "AI/ML", "skill": "GPT", "level": 2}
            ]
        },
        {
            "subject": "ê³ ê° ì´íƒˆ ì˜ˆì¸¡ ëª¨ë¸",
            "current_work": "ê³ ê° ì´íƒˆì€ ì‚¬í›„ì— íŒŒì•…ë˜ì–´ ì„ ì œì  ëŒ€ì‘ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.",
            "pain_point": "ì›”í‰ê·  5% ê³ ê° ì´íƒˆ, ì´íƒˆ ì›ì¸ íŒŒì•… ì–´ë ¤ì›€, ë¦¬í…ì…˜ ë¹„ìš© ì¦ê°€",
            "improvement_idea": "ML ëª¨ë¸ë¡œ ê³ ê° í–‰ë™ ë°ì´í„° ê¸°ë°˜ ì´íƒˆ ìœ„í—˜ë„ ì˜ˆì¸¡ ë° ë§ì¶¤í˜• ë¦¬í…ì…˜ ì „ëµ ìˆ˜ë¦½",
            "expected_effect": "ì´íƒˆë¥  30% ê°ì†Œ, ë¦¬í…ì…˜ ë¹„ìš© 40% ì ˆê°, ê³ ê° ìƒì•  ê°€ì¹˜ ì¦ëŒ€",
            "hope": "Feature engineering ì§€ì›, ëª¨ë¸ í•´ì„ ê°€ëŠ¥ì„± í™•ë³´ ì§€ì›",
            "ai_category": "ML",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 4},
                {"category": "AI/ML", "skill": "scikit-learn", "level": 3},
                {"category": "ë°ì´í„° ë¶„ì„", "skill": "SQL", "level": 4}
            ]
        },
        {
            "subject": "íšŒì˜ë¡ ìë™ ìƒì„± ì‹œìŠ¤í…œ",
            "current_work": "íšŒì˜ í›„ íšŒì˜ë¡ ì‘ì„±ì— í‰ê·  1ì‹œê°„ì´ ì†Œìš”ë˜ë©° ì‘ì„± í’ˆì§ˆì´ ì¼ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            "pain_point": "íšŒì˜ë¡ ì‘ì„± ì‹œê°„ ë¶€ë‹´, ì£¼ìš” ë‚´ìš© ëˆ„ë½, ê³µìœ  ì§€ì—°",
            "improvement_idea": "ìŒì„±ì¸ì‹ + LLMìœ¼ë¡œ íšŒì˜ ë‚´ìš© ìë™ ì „ì‚¬ ë° ìš”ì•½, ì•¡ì…˜ ì•„ì´í…œ ì¶”ì¶œ",
            "expected_effect": "íšŒì˜ë¡ ì‘ì„± ì‹œê°„ 90% ì ˆê°, ë‚´ìš© ì •í™•ë„ í–¥ìƒ, ì¦‰ì‹œ ê³µìœ  ê°€ëŠ¥",
            "hope": "ìŒì„±ì¸ì‹ ëª¨ë¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•, ìš”ì•½ í’ˆì§ˆ í–¥ìƒ ì§€ì›",
            "ai_category": "LLM",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 3},
                {"category": "AI/ML", "skill": "Speech Recognition", "level": 2}
            ]
        },
        {
            "subject": "ì¬ê³  ìµœì í™” ì¶”ì²œ ì‹œìŠ¤í…œ",
            "current_work": "ì°½ê³  ì¬ê³  ê´€ë¦¬ëŠ” ê²½í—˜ì— ì˜ì¡´í•˜ì—¬ ê³¼ì‰ ì¬ê³  ë˜ëŠ” í’ˆì ˆì´ ìì£¼ ë°œìƒí•©ë‹ˆë‹¤.",
            "pain_point": "ì¬ê³  íšŒì „ìœ¨ ì €í•˜, ì°½ê³  ê³µê°„ ë‚­ë¹„, ê¸°íšŒ ì†ì‹¤ ë°œìƒ",
            "improvement_idea": "ML ì¶”ì²œ ì‹œìŠ¤í…œìœ¼ë¡œ ìµœì  ì¬ê³  ìˆ˜ì¤€ ì˜ˆì¸¡ ë° ë°œì£¼ ì‹œì  ìë™ ì•Œë¦¼",
            "expected_effect": "ì¬ê³  ë¹„ìš© 25% ì ˆê°, í’ˆì ˆë¥  60% ê°ì†Œ, ì°½ê³  íš¨ìœ¨ì„± í–¥ìƒ",
            "hope": "ì¬ê³  ë°ì´í„° ë¶„ì„ ì§€ì›, ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶• ì§€ì›",
            "ai_category": "ML",
            "tech_capabilities": [
                {"category": "í”„ë¡œê·¸ë˜ë°", "skill": "Python", "level": 3},
                {"category": "ë°ì´í„° ë¶„ì„", "skill": "Pandas", "level": 4}
            ]
        }
    ]
    
    # Create applications
    applications = []
    grades = ["S", "A", "B", "C", "D"]
    grade_weights = [0.1, 0.3, 0.4, 0.15, 0.05]  # Sê°€ ì ê³  Bê°€ ë§ë„ë¡
    
    batch_id = "2026-1Q"
    
    for i, template in enumerate(templates, 1):
        dept = random.choice(departments)
        
        # Pre-survey (random answers)
        pre_survey = {
            "q1": random.choice(["ì˜ˆ", "ì•„ë‹ˆì˜¤"]),
            "q2": random.choice(["ì˜ˆ", "ì•„ë‹ˆì˜¤"]),
            "q3": random.choice(["ì˜ˆ", "ì•„ë‹ˆì˜¤"]),
            "q4": random.choice(["ì˜ˆ", "ì•„ë‹ˆì˜¤"]),
            "q5": random.choice(["ì˜ˆ", "ì•„ë‹ˆì˜¤"]),
            "q6": random.choice(["ì˜ˆ", "ì•„ë‹ˆì˜¤"])
        }
        
        # AI grade
        ai_grade = random.choices(grades, weights=grade_weights)[0]
        
        # AI evaluation detail
        criteria_names = [
            "ê²½ì˜ì„±ê³¼", "ì „ëµê³¼ì œ ìœ ì‚¬ë„", "í™•ì¥ê°€ëŠ¥ì„±", "ì°¸ì—¬ì ì—­ëŸ‰",
            "ì‹¤í˜„ê°€ëŠ¥ì„±", "Pain Point ëª…í™•ì„±", "ë°ì´í„° ì¤€ë¹„ë„", "ROI ì¸¡ì • ê°€ëŠ¥ì„±"
        ]
        
        grade_to_score = {"S": 5, "A": 4, "B": 3, "C": 2, "D": 1}
        base_score = grade_to_score[ai_grade]
        
        evaluation_detail = {}
        for criteria in criteria_names:
            score = max(1, min(5, base_score + random.randint(-1, 1)))
            criteria_grade = [g for g, s in grade_to_score.items() if s == score][0]
            evaluation_detail[criteria] = {
                "grade": criteria_grade,
                "score": score,
                "comment": f"{criteria}ì— ëŒ€í•œ í‰ê°€ ì½”ë©˜íŠ¸ì…ë‹ˆë‹¤."
            }
        
        # AI summary
        ai_summary = f"""- {template['subject']} í”„ë¡œì íŠ¸
- ì£¼ìš” Pain Point: {template['pain_point'][:50]}...
- ê¸°ëŒ€ íš¨ê³¼: {template['expected_effect'][:50]}...
- AI ê¸°ìˆ : {template['ai_category']}
- ì¢…í•© í‰ê°€: {ai_grade}ë“±ê¸‰"""
        
        # AI categories
        ai_categories = [
            {"category": template["ai_category"], "priority": 1, "confidence": 0.9}
        ]
        
        # User evaluation (50% of applications)
        user_grade = None
        user_comment = None
        user_evaluated_by = None
        user_evaluated_at = None
        status = "ai_evaluated"
        
        if random.random() < 0.5:
            # Find reviewer for this department
            reviewer = next((r for r in reviewers if r.department_id == dept.id), None)
            if reviewer:
                user_grade = random.choices(grades, weights=grade_weights)[0]
                user_comment = f"ì‹¬ì‚¬ìœ„ì› í‰ê°€ ì˜ê²¬: ë³¸ ê³¼ì œëŠ” {user_grade}ë“±ê¸‰ìœ¼ë¡œ í‰ê°€ë˜ì—ˆìŠµë‹ˆë‹¤."
                user_evaluated_by = reviewer.id
                user_evaluated_at = datetime.utcnow() - timedelta(days=random.randint(1, 10))
                status = "user_evaluated"
        
        app = Application(
            confluence_page_id=f"DUMMY{i:03d}",
            confluence_page_url=f"https://confluence.company.com/pages/viewpage.action?pageId=DUMMY{i:03d}",
            subject=template["subject"],
            division=dept.name,
            department_id=dept.id,
            participant_count=random.randint(2, 8),
            representative_name=f"ê¹€{chr(0xAC00 + random.randint(0, 100))}ë™",
            representative_knox_id=f"user{i:03d}",
            pre_survey=pre_survey,
            current_work=template["current_work"],
            pain_point=template["pain_point"],
            improvement_idea=template["improvement_idea"],
            expected_effect=template["expected_effect"],
            hope=template["hope"],
            tech_capabilities=template["tech_capabilities"],
            ai_category_primary=template["ai_category"],
            ai_categories=ai_categories,
            ai_grade=ai_grade,
            ai_summary=ai_summary,
            ai_evaluation_detail=evaluation_detail,
            ai_evaluated_at=datetime.utcnow() - timedelta(days=random.randint(5, 15)),
            user_grade=user_grade,
            user_comment=user_comment,
            user_evaluated_by=user_evaluated_by,
            user_evaluated_at=user_evaluated_at,
            batch_id=batch_id,
            status=status,
            created_at=datetime.utcnow() - timedelta(days=random.randint(15, 30))
        )
        
        db.add(app)
        db.flush()
        applications.append(app)
        
        # Add AI evaluation history
        ai_history = EvaluationHistory(
            application_id=app.id,
            evaluator_id=None,
            evaluator_type="AI",
            grade=ai_grade,
            summary=ai_summary,
            evaluation_detail=evaluation_detail,
            ai_categories=ai_categories,
            created_at=app.ai_evaluated_at
        )
        db.add(ai_history)
        
        # Add user evaluation history if exists
        if user_evaluated_by:
            user_history = EvaluationHistory(
                application_id=app.id,
                evaluator_id=user_evaluated_by,
                evaluator_type="USER",
                grade=user_grade,
                summary=user_comment,
                evaluation_detail=None,
                ai_categories=ai_categories,
                created_at=user_evaluated_at
            )
            db.add(user_history)
    
    db.commit()
    print(f"âœ… Created {len(applications)} applications with evaluation histories")
    print(f"ğŸ“Š Grade distribution:")
    for grade in grades:
        count = sum(1 for app in applications if app.ai_grade == grade)
        print(f"   {grade}: {count} ({count/len(applications)*100:.1f}%)")
    
    print(f"ğŸ‘¥ User evaluations: {sum(1 for app in applications if app.user_grade is not None)}/{len(applications)}")
    print("âœ… Dummy data generation completed!")


if __name__ == "__main__":
    from app.database import SessionLocal
    db = SessionLocal()
    try:
        generate_dummy_data(db)
    finally:
        db.close()

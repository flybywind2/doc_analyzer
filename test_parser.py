#!/usr/bin/env python3
"""
Test Confluence Parser with sample HTML
"""
import sys
import re
from pathlib import Path
from typing import Dict, Any, Optional
from bs4 import BeautifulSoup
import json


def parse_application(html_content: str, page_id: str = "test", page_url: str = "http://test") -> Dict[str, Any]:
    """
    Parse application data from HTML content
    (Standalone version for testing without app dependencies)
    """
    soup = BeautifulSoup(html_content, 'lxml')
    data = {
        "confluence_page_id": page_id,
        "confluence_page_url": page_url,
        "parse_error_log": ""
    }
    errors = []

    try:
        # ============================================================
        # I. ê¸°ë³¸ì‚¬í•­ íŒŒì‹±
        # ============================================================

        # ê³¼ì œëª… (class="subject") - ì…€ ì•ˆì— ì§ì ‘ ë‚´ìš©ì´ ìˆìŒ
        subject_elem = soup.find(class_="subject")
        if subject_elem:
            text = subject_elem.get_text(strip=True)
            if text and text != "ì—¬ê¸° íŒŒì‹±":
                data["subject"] = text

        # ì†Œì†/ì‚¬ì—…ë¶€ (class="division") - ì…€ ì•ˆì— ì§ì ‘ ë‚´ìš©ì´ ìˆìŒ
        division_elem = soup.find(class_="division")
        if division_elem:
            text = division_elem.get_text(strip=True)
            if text and text != "ì—¬ê¸° íŒŒì‹±":
                data["division"] = text

        # ì°¸ì—¬ì¸ì› (class="dept") - ì…€ ì•ˆì— ì§ì ‘ ë‚´ìš©ì´ ìˆìŒ
        dept_elem = soup.find(class_="dept")
        if dept_elem:
            dept_text = dept_elem.get_text(strip=True)
            if dept_text and dept_text != "ì—¬ê¸° íŒŒì‹±":
                # ìˆ«ìë§Œ ì¶”ì¶œ
                numbers = re.findall(r'\d+', dept_text)
                if numbers:
                    data["participant_count"] = int(numbers[0])

        # ê³¼ì œ ëŒ€í‘œì - "ê³¼ì œ ëŒ€í‘œì" í—¤ë”ë¥¼ ì°¾ê³  ê°™ì€ í–‰ì˜ ë‹¤ìŒ ì…€ì—ì„œ ë‚´ìš© ì¶”ì¶œ
        rep_header_elem = soup.find('strong', string=re.compile(r'ê³¼ì œ\s*ëŒ€í‘œì'))
        if rep_header_elem:
            header_cell = rep_header_elem.find_parent('td')
            if header_cell:
                # ê°™ì€ í–‰ì˜ ë‹¤ìŒ ì…€ë“¤ í™•ì¸
                next_cells = header_cell.find_next_siblings('td')
                for cell in next_cells:
                    text = cell.get_text(strip=True)
                    if text and text != "ì—¬ê¸° íŒŒì‹±" and len(text) > 0:
                        # "ì´ë¦„ (Knox ID)" ë˜ëŠ” "ì´ë¦„ Knox ID" í˜•ì‹ íŒŒì‹±
                        match = re.match(r'(.+?)\s*[\(ï¼ˆ](.+?)[\)ï¼‰]', text)
                        if match:
                            data["representative_name"] = match.group(1).strip()
                            data["representative_knox_id"] = match.group(2).strip()
                        else:
                            parts = text.split()
                            if len(parts) >= 2:
                                data["representative_name"] = parts[0]
                                data["representative_knox_id"] = parts[1]
                            elif len(parts) == 1:
                                data["representative_name"] = parts[0]
                        break

        # ============================================================
        # II. ì‚¬ì „ ì„¤ë¬¸ íŒŒì‹±
        # ============================================================
        pre_survey = {}
        for i in range(1, 7):
            q_elem = soup.find(class_=f"q{i}")
            if q_elem:
                row = q_elem.find_parent('tr')
                if row:
                    cells = row.find_all('td')
                    q_index = -1
                    for idx, cell in enumerate(cells):
                        if f"q{i}" in cell.get('class', []):
                            q_index = idx
                            break

                    if q_index >= 0:
                        q_text = cells[q_index].get_text(strip=True)
                        next_text = cells[q_index + 1].get_text(strip=True) if q_index + 1 < len(cells) else ""

                        if q_text and q_text not in ['', 'O', 'X']:
                            pre_survey[f"q{i}"] = "ì˜ˆ"
                        elif next_text and next_text not in ['', 'O', 'X']:
                            pre_survey[f"q{i}"] = "ì•„ë‹ˆì˜¤"
                        elif 'O' in q_text or 'â—‹' in q_text or 'âœ“' in q_text:
                            pre_survey[f"q{i}"] = "ì˜ˆ"
                        elif 'O' in next_text or 'â—‹' in next_text or 'âœ“' in next_text:
                            pre_survey[f"q{i}"] = "ì•„ë‹ˆì˜¤"

        if pre_survey:
            data["pre_survey"] = pre_survey

        # ============================================================
        # III. ì‹ ì²­ ë‚´ìš© íŒŒì‹±
        # ============================================================
        def find_section_content(section_number: str, section_keyword: str) -> Optional[str]:
            """ì„¹ì…˜ ë²ˆí˜¸ì™€ í‚¤ì›Œë“œë¡œ ë‚´ìš©ì„ ì°¾ëŠ” í•¨ìˆ˜"""
            for td in soup.find_all('td', class_='highlight-#b3d4ff'):
                td_text = td.get_text(strip=True)
                if section_number in td_text and section_keyword in td_text:
                    header_row = td.find_parent('tr')
                    if header_row:
                        next_row = header_row.find_next_sibling('tr')
                        if next_row:
                            content_row = next_row.find_next_sibling('tr')
                            if content_row:
                                content_cell = content_row.find('td')
                                if content_cell:
                                    text = content_cell.get_text(strip=True)
                                    if text and text != "ì—¬ê¸° íŒŒì‹±":
                                        return text
            return None

        # í˜„ì¬ ì—…ë¬´
        current_work = find_section_content("1.", "í˜„ì¬ ì—…ë¬´")
        if current_work:
            data["current_work"] = current_work

        # Pain Point
        pain_point = find_section_content("2.", "Pain point")
        if pain_point:
            data["pain_point"] = pain_point

        # ê°œì„  ì•„ì´ë””ì–´
        improvement_idea = find_section_content("3.", "ê°œì„  ì•„ì´ë””ì–´")
        if improvement_idea:
            data["improvement_idea"] = improvement_idea

        # ê¸°ëŒ€ íš¨ê³¼
        expected_effect = find_section_content("4.", "ê¸°ëŒ€ íš¨ê³¼")
        if expected_effect:
            data["expected_effect"] = expected_effect

        # ë°”ë¼ëŠ” ì 
        hope = find_section_content("5.", "ë°”ë¼ëŠ” ì ")
        if hope:
            data["hope"] = hope

        # ============================================================
        # IV. ê³¼ì œ ì°¸ì—¬ì ê¸°ìˆ  ì—­ëŸ‰ íŒŒì‹±
        # ============================================================
        tech_capabilities = []

        tech_header = soup.find('strong', string=re.compile(r'IV\.\s*ê³¼ì œ\s*ì°¸ì—¬ì\s*ê¸°ìˆ \s*ì—­ëŸ‰'))
        if tech_header:
            main_table = tech_header.find_parent('table')
            if main_table:
                nested_table = main_table.find('table', class_='wrapped')
                if nested_table:
                    current_category = None

                    rows = nested_table.find_all('tr')
                    for row in rows:
                        cells = row.find_all('td')

                        if len(cells) > 0:
                            first_cell_text = cells[0].get_text(strip=True)
                            if 'ë¶„ì•¼' in first_cell_text or 'ë ˆë²¨' in first_cell_text:
                                continue

                        # ëŒ€ë¶„ë¥˜ í–‰
                        if len(cells) == 1 and cells[0].get('colspan') == '9':
                            category_text = cells[0].get_text(strip=True)
                            if category_text and category_text not in ['(ì‘ì„± ì˜ˆì‹œ)', '']:
                                current_category = category_text
                            continue

                        # ìƒì„¸ í–‰
                        if len(cells) >= 2:
                            cell_idx = 0
                            field = None
                            skill = None
                            level_text = None

                            if cell_idx < len(cells):
                                field_cell = cells[cell_idx]
                                field = field_cell.get_text(strip=True)
                                cell_idx += 1

                            if cell_idx < len(cells):
                                skill_cell = cells[cell_idx]
                                skill = skill_cell.get_text(strip=True)
                                cell_idx += 1

                            if cell_idx < len(cells):
                                level_cell = cells[cell_idx]
                                level_text = level_cell.get_text(strip=True)

                            if field and skill and level_text:
                                if 'ì‘ì„± ì˜ˆì‹œ' in field or 'ì‘ì„± ì˜ˆì‹œ' in skill:
                                    continue
                                if field == 'ì—¬ê¸° íŒŒì‹±' or skill == 'ì—¬ê¸° íŒŒì‹±':
                                    continue

                                field_elem = cells[0].find('em')
                                skill_elem = cells[1].find('em') if len(cells) > 1 else None
                                if field_elem or skill_elem:
                                    continue

                                level_numbers = re.findall(r'\d+', level_text)
                                level = int(level_numbers[0]) if level_numbers else 0

                                if level > 0:
                                    tech_capabilities.append({
                                        "category": current_category or field,
                                        "field": field,
                                        "skill": skill,
                                        "level": level
                                    })

        if tech_capabilities:
            data["tech_capabilities"] = tech_capabilities

    except Exception as e:
        error_msg = f"Parsing error: {str(e)}"
        errors.append(error_msg)
        print(f"âŒ {error_msg}")
        import traceback
        errors.append(traceback.format_exc())

    if errors:
        data["parse_error_log"] = "\n".join(errors)

    return data


def test_parse_html():
    """Test parsing with conf.html"""

    # Read sample HTML
    html_file = Path("conf.html")
    if not html_file.exists():
        print("âŒ conf.html not found")
        return

    with open(html_file, 'r', encoding='utf-8') as f:
        html_content = f.read()

    # Parse
    print("ğŸ” Parsing HTML...")
    result = parse_application(html_content, "test_page_id", "http://test.url")

    # Display results
    print("\n" + "=" * 60)
    print("ğŸ“Š Parsing Results")
    print("=" * 60)

    print(f"\nâœ… Subject: {result.get('subject', 'N/A')}")
    print(f"âœ… Division: {result.get('division', 'N/A')}")
    print(f"âœ… Participant Count: {result.get('participant_count', 'N/A')}")
    print(f"âœ… Representative: {result.get('representative_name', 'N/A')} ({result.get('representative_knox_id', 'N/A')})")

    print(f"\nğŸ“‹ Pre-Survey:")
    for key, value in result.get('pre_survey', {}).items():
        print(f"  {key}: {value}")

    print(f"\nğŸ“ Application Content:")
    print(f"  Current Work: {result.get('current_work', 'N/A')[:100]}...")
    print(f"  Pain Point: {result.get('pain_point', 'N/A')[:100]}...")
    print(f"  Improvement Idea: {result.get('improvement_idea', 'N/A')[:100]}...")
    print(f"  Expected Effect: {result.get('expected_effect', 'N/A')[:100]}...")
    print(f"  Hope: {result.get('hope', 'N/A')[:100]}...")

    print(f"\nğŸ› ï¸  Tech Capabilities ({len(result.get('tech_capabilities', []))} items):")
    for i, tech in enumerate(result.get('tech_capabilities', [])[:10], 1):
        print(f"  {i}. [{tech.get('category', 'N/A')}] {tech.get('field', 'N/A')} - {tech.get('skill', 'N/A')}: Level {tech.get('level', 0)}")

    if result.get('parse_error_log'):
        print(f"\nâš ï¸  Parse Errors:")
        print(result['parse_error_log'])

    print("\n" + "=" * 60)
    print("ğŸ’¾ Full JSON Output:")
    print("=" * 60)
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    test_parse_html()
